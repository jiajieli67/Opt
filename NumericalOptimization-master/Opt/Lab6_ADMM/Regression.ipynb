{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Regression Problem\n",
    "\n",
    "We are given a set of $m = 300$ observations, each comprised of 27 *features* $(a_i)$ representing a student characteristics and an objective value $(b_i)$ representing its final grade. In this lab, the *squared 2-norm* is used as loss to form the following optimization problem\n",
    "\\begin{align*}\n",
    "\\min_{x\\in\\mathbb{R}^d } l(x) := \\frac{1}{m}  \\sum_{i=1}^m (\\langle a_i,x \\rangle - b_i)^2  = \\frac{1}{m} \\|Ax-b\\|_2^2 .\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "In previous labs, we considered:\n",
    "- $\\ell_2$ regularization to prevent overfitting. The whole function was smooth and thus gradient algorithms were efficient. \n",
    "- $\\ell_1$ regularization to promote sparsity of the iterates. After separation of the smooth  and non-smooth parts of the loss, we used the proximal gradient algorithm.\n",
    "- efficient libraries for solving linear and quadratic programs.\n",
    "\n",
    "**Objective of this lab:**  We introduce a new regularizer: the *group sparsity norm* which has an explicit proximal operator but makes the problem not a QP problem anymore. We will use our previous knowledges about proximity operators, efficient QP solving, and new knowledge about splitting algorithms (as ADMM) to efficiently solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Sparsity ($\\ell_1/\\ell_2$ norm)\n",
    "\n",
    "We introduce as a regularizer the group sparsity norm (also called $\\ell_1/\\ell_2$ norm) which writes as the sum of the (non-squared) 2-norm of groups of coordinates:\n",
    "$$ g(x) = \\sum_{g\\in\\mathcal{G} } \\| x_g\\|_2 $$\n",
    "where for a group of indexes $g$, $x_g = [x_i]_{i\\in g}$.\n",
    "\n",
    "For instance, in our  *student performance* dataset, we can group features as such:\n",
    "1. $(1,2)$ physical characteristics.\n",
    "2. $(3,4,5,6,7,8)$ home environment.\n",
    "3. $(9,10,11,12,13)$ studying habits.\n",
    "4. $(14,15,16)$ misc.\n",
    "5. $(17,18,19,20,21,22,23,24)$ social.\n",
    "6. $(25,26,27)$ attendence and grades.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Full problem \n",
    "\n",
    "\n",
    "The whole learning problem for this lab reformulates as: \n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{x\\in\\mathbb{R}^d } F(x) := \\underbrace{ \\frac{1}{m} \\|Ax-b\\|_2^2 }_{f(x)} + \\underbrace{\\lambda_g \\sum_{g\\in\\mathcal{G} } \\| x_g\\|_2}_{g(x)}.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "### Features signification \n",
    "\n",
    "The dataset is comprised of $27$ features described below and the goal is to predict if the student may pass its year or not. It is thus of importance to investigate which features are the most significant for the student success. We will see how the regularization can help to this goal."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 sex - student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "2 age - student's age (numeric: from 15 to 22)\n",
    "3 address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "4 famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "5 Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "6 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "7 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "8 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "9 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "10 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "11 schoolsup - extra educational support (binary: yes or no)\n",
    "12 famsup - family educational support (binary: yes or no)\n",
    "13 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "14 activities - extra-curricular activities (binary: yes or no)\n",
    "15 nursery - attended nursery school (binary: yes or no)\n",
    "16 higher - wants to take higher education (binary: yes or no)\n",
    "17 internet - Internet access at home (binary: yes or no)\n",
    "18 romantic - with a romantic relationship (binary: yes or no)\n",
    "19 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "20 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "21 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "22 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "23 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "24 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "25 absences - number of school absences (numeric: from 0 to 93)\n",
    "26 G1 - first period grade (numeric: from 0 to 20)\n",
    "27 G2 - second period grade (numeric: from 0 to 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#### File reading\n",
    "dat_file = np.load('student.npz')\n",
    "A = dat_file['A_learn']\n",
    "b = dat_file['b_learn']\n",
    "m = b.size\n",
    "\n",
    "\n",
    "A_test = dat_file['A_test']\n",
    "b_test = dat_file['b_test']\n",
    "m_test = b_test.size\n",
    "\n",
    "\n",
    "d = 27 # features\n",
    "n = d+1 # with the intercept\n",
    "\n",
    "lamG = 0.5 # for the regularization best:0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = [[ 1,2],\n",
    "     [3,4,5,6,7,8],\n",
    "     [9,10,11,12,13],\n",
    "     [14,15,16],\n",
    "     [17,18,19,20,21,22,23,24],\n",
    "     [25,26,27]] \n",
    "\n",
    "n_g = len(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracles\n",
    "\n",
    "\n",
    "> The prox operator for function $f$ has to be completed in `f_prox` using `cvxopt`'s QP solver.\n",
    "\n",
    "> The prox operator for function $g$ is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def f(x):\n",
    "    return np.linalg.norm(np.dot(A,x)-b)**2/float(m)\n",
    "\n",
    "def f_prox(x,gamma):\n",
    "    \n",
    "    P = 0.0 # TODO\n",
    "    q = 0.0 # TODO\n",
    "    \n",
    "    sol=solvers.qp(P,q) \n",
    "    p = sol['x']\n",
    "    return np.squeeze(np.array(p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    g = 0\n",
    "    for i in range(n_g):\n",
    "        g += np.linalg.norm(x[G[i]],2)\n",
    "    return lamG*g\n",
    "\n",
    "def g_prox(x,gamma):\n",
    "    p = np.copy(x)\n",
    "    for i in range(n_g):\n",
    "        if  np.linalg.norm(x[G[i]],2) < - lamG*gamma:\n",
    "            p[G[i]] = x[G[i]]*(1 + lamG*gamma/np.linalg.norm(x[G[i]],2))\n",
    "        elif np.linalg.norm(x[G[i]],2) > lamG*gamma:\n",
    "            p[G[i]] = x[G[i]]*(1 - lamG*gamma/np.linalg.norm(x[G[i]],2))\n",
    "        else:\n",
    "            p[G[i]] = np.zeros(len(G[i]))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return f(x) + g(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Functions\n",
    "\n",
    "They are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def prediction_train(w,PRINT):\n",
    "\n",
    "    pred = np.dot(A,w)\n",
    "    perf = 0\n",
    "    \n",
    "    for i in range(A.shape[0]):\n",
    "        if PRINT:\n",
    "                print(\"True grade: {:d} \\t-- Predicted: {:.1f} \".format(int(b[i]),pred[i]))\n",
    "        perf += np.abs(pred[i]-b[i]) \n",
    "\n",
    "    return pred,float(perf)/A.shape[0]\n",
    "\n",
    "\n",
    "def prediction_test(w,PRINT):\n",
    "\n",
    "    pred = np.dot(A_test,w)\n",
    "    perf = 0\n",
    "    \n",
    "    for i in range(A_test.shape[0]):\n",
    "        if PRINT:\n",
    "                print(\"True grade: {:d} \\t-- Predicted: {:.1f} \".format(int(b_test[i]),pred[i]))\n",
    "        perf += np.abs(pred[i]-b_test[i]) \n",
    "\n",
    "    return pred,float(perf)/A_test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
